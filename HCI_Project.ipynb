{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "b51f73d6-b7a5-43b5-ace7-ae59670496a4",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: mediapipe in d:\\software\\anaconda3\\lib\\site-packages (0.9.0)\n",
      "Requirement already satisfied: flatbuffers>=2.0 in d:\\software\\anaconda3\\lib\\site-packages (from mediapipe) (22.10.26)\n",
      "Requirement already satisfied: numpy in d:\\software\\anaconda3\\lib\\site-packages (from mediapipe) (1.20.3)\n",
      "Requirement already satisfied: absl-py in d:\\software\\anaconda3\\lib\\site-packages (from mediapipe) (1.3.0)\n",
      "Requirement already satisfied: attrs>=19.1.0 in d:\\software\\anaconda3\\lib\\site-packages (from mediapipe) (21.2.0)\n",
      "Requirement already satisfied: protobuf<4,>=3.11 in d:\\software\\anaconda3\\lib\\site-packages (from mediapipe) (3.20.3)\n",
      "Requirement already satisfied: matplotlib in d:\\software\\anaconda3\\lib\\site-packages (from mediapipe) (3.4.3)\n",
      "Requirement already satisfied: opencv-contrib-python in d:\\software\\anaconda3\\lib\\site-packages (from mediapipe) (4.6.0.66)\n",
      "Requirement already satisfied: pyparsing>=2.2.1 in d:\\software\\anaconda3\\lib\\site-packages (from matplotlib->mediapipe) (3.0.4)\n",
      "Requirement already satisfied: pillow>=6.2.0 in d:\\software\\anaconda3\\lib\\site-packages (from matplotlib->mediapipe) (8.4.0)\n",
      "Requirement already satisfied: python-dateutil>=2.7 in d:\\software\\anaconda3\\lib\\site-packages (from matplotlib->mediapipe) (2.8.2)\n",
      "Requirement already satisfied: kiwisolver>=1.0.1 in d:\\software\\anaconda3\\lib\\site-packages (from matplotlib->mediapipe) (1.3.1)\n",
      "Requirement already satisfied: cycler>=0.10 in d:\\software\\anaconda3\\lib\\site-packages (from matplotlib->mediapipe) (0.10.0)\n",
      "Requirement already satisfied: six in d:\\software\\anaconda3\\lib\\site-packages (from cycler>=0.10->matplotlib->mediapipe) (1.16.0)\n",
      "Requirement already satisfied: dollarpy in d:\\software\\anaconda3\\lib\\site-packages (0.1.1)\n"
     ]
    }
   ],
   "source": [
    "!pip install mediapipe\n",
    "!pip install dollarpy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "9c70279d-492d-4f80-bd02-2a76d18f7e83",
   "metadata": {},
   "outputs": [],
   "source": [
    "import mediapipe as mp\n",
    "import cv2\n",
    "import csv\n",
    "from dollarpy import Point, Recognizer , Template\n",
    "import os\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "ca9d60d4-10f0-4719-8020-09ebf72c0c68",
   "metadata": {},
   "outputs": [],
   "source": [
    "mp_holistic = mp.solutions.holistic\n",
    "mp_drawing = mp.solutions.drawing_utils\n",
    "mp_drawing_styles = mp.solutions.drawing_styles"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "661fba7f-92c2-47cd-9afd-bf9965ba21dc",
   "metadata": {},
   "outputs": [],
   "source": [
    "def getPoints(videoPath) :\n",
    "  left_leg      =[]\n",
    "  right_leg     =[]\n",
    "  \n",
    "  face          =[]\n",
    "  #left_wrist    =[]\n",
    "  #right_wrist   =[]\n",
    "\n",
    "  \n",
    "  left_arm    =[]\n",
    "  right_arm   =[]\n",
    "  \n",
    "  left_shoulder =[]\n",
    "  right_shoulder=[]\n",
    "\n",
    "  #left_elbow    =[]\n",
    "  #right_elbow   =[]\n",
    "\n",
    "  #left_hip      =[]\n",
    "  #right_hip     =[]\n",
    "\n",
    "\n",
    "\n",
    "  points        =[]\n",
    "  with mp_holistic.Holistic(static_image_mode=True, min_detection_confidence = 0.7) as Holistic:\n",
    "    video = cv2.VideoCapture(videoPath)\n",
    "    while video.isOpened():\n",
    "      ret , frame = video.read()\n",
    "      if ret == True:\n",
    "        image = cv2.cvtColor(frame,cv2.COLOR_BGR2RGB)\n",
    "        image.flags.writeable = False\n",
    "        results = Holistic.process(cv2.flip(image,1))\n",
    "        if results.pose_landmarks:\n",
    "          #leg includes ankle,knee and hip\n",
    "          #left_leg.append(Point(results.pose_landmarks.landmark[mp_holistic.PoseLandmark.LEFT_ANKLE].x,results.pose_landmarks.landmark[mp_holistic.PoseLandmark.LEFT_ANKLE].y,2))\n",
    "          #left_leg.append(Point(results.pose_landmarks.landmark[mp_holistic.PoseLandmark.LEFT_KNEE].x,results.pose_landmarks.landmark[mp_holistic.PoseLandmark.LEFT_KNEE].y,2))\n",
    "          #left_leg.append(Point(results.pose_landmarks.landmark[mp_holistic.PoseLandmark.LEFT_HIP].x,results.pose_landmarks.landmark[mp_holistic.PoseLandmark.LEFT_HIP].y,2))\n",
    "          \n",
    "          face.append(Point(results.pose_landmarks.landmark[mp_holistic.PoseLandmark.RIGHT_EAR].x,results.pose_landmarks.landmark[mp_holistic.PoseLandmark.RIGHT_EAR].y,2))\n",
    "          face.append(Point(results.pose_landmarks.landmark[mp_holistic.PoseLandmark.NOSE].x,results.pose_landmarks.landmark[mp_holistic.PoseLandmark.NOSE].y,2))\n",
    "          #arm includes shoulder, elbow and wrist\n",
    "          #left_arm.append(Point(results.pose_landmarks.landmark[mp_holistic.PoseLandmark.LEFT_SHOULDER].x,results.pose_landmarks.landmark[mp_holistic.PoseLandmark.LEFT_SHOULDER].y,2))\n",
    "          #left_arm.append(Point(results.pose_landmarks.landmark[mp_holistic.PoseLandmark.LEFT_ELBOW].x,results.pose_landmarks.landmark[mp_holistic.PoseLandmark.LEFT_ELBOW].y,2))\n",
    "          #left_arm.append(Point(results.pose_landmarks.landmark[mp_holistic.PoseLandmark.LEFT_WRIST].x,results.pose_landmarks.landmark[mp_holistic.PoseLandmark.LEFT_WRIST].y,2))\n",
    "\n",
    "          #right_arm.append(Point(results.pose_landmarks.landmark[mp_holistic.PoseLandmark.RIGHT_SHOULDER].x,results.pose_landmarks.landmark[mp_holistic.PoseLandmark.RIGHT_SHOULDER].y,2))\n",
    "          #right_arm.append(Point(results.pose_landmarks.landmark[mp_holistic.PoseLandmark.RIGHT_ELBOW].x,results.pose_landmarks.landmark[mp_holistic.PoseLandmark.RIGHT_ELBOW].y,2))\n",
    "          #right_arm.append(Point(results.pose_landmarks.landmark[mp_holistic.PoseLandmark.RIGHT_WRIST].x,results.pose_landmarks.landmark[mp_holistic.PoseLandmark.RIGHT_WRIST].y,2))\n",
    "\n",
    "\n",
    "          #right_leg.append(Point(results.pose_landmarks.landmark[mp_holistic.PoseLandmark.RIGHT_ANKLE].x,results.pose_landmarks.landmark[mp_holistic.PoseLandmark.RIGHT_ANKLE].y,2))\n",
    "          #right_leg.append(Point(results.pose_landmarks.landmark[mp_holistic.PoseLandmark.RIGHT_KNEE].x,results.pose_landmarks.landmark[mp_holistic.PoseLandmark.RIGHT_KNEE].y,2))\n",
    "          #right_leg.append(Point(results.pose_landmarks.landmark[mp_holistic.PoseLandmark.RIGHT_HIP].x,results.pose_landmarks.landmark[mp_holistic.PoseLandmark.RIGHT_HIP].y,2))\n",
    "\n",
    "      else:\n",
    "        break\n",
    "    points = face\n",
    "    return points"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "1757122d-654b-4343-a3ea-73227276f1f5",
   "metadata": {},
   "outputs": [],
   "source": [
    "classes = []"
   ]
  },
  {
   "cell_type": "raw",
   "id": "9aba4897-c19e-4c1c-9bc4-08ee42687b35",
   "metadata": {},
   "source": [
    "vid = \"./Poses/Nodding.flv\"\n",
    "pts = getPoints(vid)\n",
    "tmp = Template('yes' ,pts)\n",
    "classes.append(tmp)\n",
    "\n",
    "vid = \"./Poses/Shaking_head1.flv\" \n",
    "pts = getPoints(vid)\n",
    "tmp = Template('no' ,pts)\n",
    "classes.append(tmp)\n",
    "\n",
    "vid = \"./Poses/Shaking_head2.flv\"\n",
    "pts = getPoints(vid)\n",
    "tmp = Template('no' ,pts)\n",
    "classes.append(tmp)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "76bba5dc-c94d-484a-aae8-61783893c1c0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1669053215.8985927\n",
      "(None, 0)\n"
     ]
    }
   ],
   "source": [
    "vid = \"./Poses/Test2.mkv\"\n",
    "pts = getPoints(vid)\n",
    "\n",
    "import time\n",
    "start = time.time()\n",
    "reco = Recognizer(classes)\n",
    "predicted = reco.recognize(pts)\n",
    "print(start)\n",
    "print(predicted)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "12c2d25c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: imutils in d:\\software\\anaconda3\\lib\\site-packages (0.5.4)\n"
     ]
    }
   ],
   "source": [
    "!pip install imutils"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "b2664114",
   "metadata": {},
   "outputs": [],
   "source": [
    "# import the necessary packages\n",
    "from collections import deque\n",
    "from imutils.video import VideoStream\n",
    "import numpy as np\n",
    "import argparse\n",
    "import cv2\n",
    "import imutils\n",
    "import time\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "6277d50f",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "usage: ipykernel_launcher.py [-h] [-v VIDEO] [-b BUFFER]\n",
      "ipykernel_launcher.py: error: unrecognized arguments: -f C:\\Users\\dell\\AppData\\Roaming\\jupyter\\runtime\\kernel-7e5bed94-6c80-4c6a-90a0-64c949e2bc0e.json\n"
     ]
    },
    {
     "ename": "SystemExit",
     "evalue": "2",
     "output_type": "error",
     "traceback": [
      "An exception has occurred, use %tb to see the full traceback.\n",
      "\u001b[1;31mSystemExit\u001b[0m\u001b[1;31m:\u001b[0m 2\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "D:\\software\\anaconda3\\lib\\site-packages\\IPython\\core\\interactiveshell.py:3452: UserWarning: To exit: use 'exit', 'quit', or Ctrl-D.\n",
      "  warn(\"To exit: use 'exit', 'quit', or Ctrl-D.\", stacklevel=1)\n"
     ]
    }
   ],
   "source": [
    "# construct the argument parse and parse the arguments\n",
    "ap = argparse.ArgumentParser()\n",
    "ap.add_argument(\"-v\", \"--video\",\n",
    "\thelp=\"path to the (optional) video file\")\n",
    "ap.add_argument(\"-b\", \"--buffer\", type=int, default=64,\n",
    "\thelp=\"max buffer size\")\n",
    "args = vars(ap.parse_args())\n",
    "# define the lower and upper boundaries of the \"green\"\n",
    "# ball in the HSV color space, then initialize the\n",
    "# list of tracked points\n",
    "ColorLower = (0,0,0)\n",
    "ColorUpper = (235, 235, 235)\n",
    "pts = deque(maxlen=args[\"buffer\"])\n",
    "# if a video path was not supplied, grab the reference\n",
    "# to the webcam\n",
    "if not args.get(\"video\", False):\n",
    "\tvs = VideoStream(src=0).start()\n",
    "# otherwise, grab a reference to the video file\n",
    "else:\n",
    "\tvs = cv2.VideoCapture(args[\"video\"])\n",
    "# allow the camera or video file to warm up\n",
    "time.sleep(2.0)\n",
    "# keep looping\n",
    "while True:\n",
    "\t# grab the current frame\n",
    "\tframe = vs.read()\n",
    "\t# handle the frame from VideoCapture or VideoStream\n",
    "\tframe = frame[1] if args.get(\"video\", False) else frame\n",
    "\t# if we are viewing a video and we did not grab a frame,\n",
    "\t# then we have reached the end of the video\n",
    "\tif frame is None:\n",
    "\t\tbreak\n",
    "\t# resize the frame, blur it, and convert it to the HSV\n",
    "\t# color space\n",
    "\tframe = imutils.resize(frame, width=600)\n",
    "\tblurred = cv2.GaussianBlur(frame, (11, 11), 0)\n",
    "\thsv = cv2.cvtColor(blurred, cv2.COLOR_BGR2HSV)\n",
    "\t# construct a mask for the color \"green\", then perform\n",
    "\t# a series of dilations and erosions to remove any small\n",
    "\t# blobs left in the mask\n",
    "\tmask = cv2.inRange(hsv, ColorLower, ColorUpper)\n",
    "\tmask = cv2.erode(mask, None, iterations=2)\n",
    "\tmask = cv2.dilate(mask, None, iterations=2)\n",
    "  # find contours in the mask and initialize the current\n",
    "\t# (x, y) center of the ball\n",
    "\tcnts = cv2.findContours(mask.copy(), cv2.RETR_EXTERNAL,\n",
    "\t\tcv2.CHAIN_APPROX_SIMPLE)\n",
    "\tcnts = imutils.grab_contours(cnts)\n",
    "\tcenter = None\n",
    "\t# only proceed if at least one contour was found\n",
    "\tif len(cnts) > 0:\n",
    "\t\t# find the largest contour in the mask, then use\n",
    "\t\t# it to compute the minimum enclosing circle and\n",
    "\t\t# centroid\n",
    "\t\tc = max(cnts, key=cv2.contourArea)\n",
    "\t\t((x, y), radius) = cv2.minEnclosingCircle(c)\n",
    "\t\tM = cv2.moments(c)\n",
    "\t\tcenter = (int(M[\"m10\"] / M[\"m00\"]), int(M[\"m01\"] / M[\"m00\"]))\n",
    "\t\t# only proceed if the radius meets a minimum size\n",
    "\t\tif radius > 10:\n",
    "\t\t\t# draw the circle and centroid on the frame,\n",
    "\t\t\t# then update the list of tracked points\n",
    "\t\t\tcv2.circle(frame, (int(x), int(y)), int(radius),\n",
    "\t\t\t\t(0, 255, 255), 2)\n",
    "\t\t\tcv2.circle(frame, center, 5, (0, 0, 255), -1)\n",
    "\t# update the points queue\n",
    "\tpts.appendleft(center)\n",
    "  # loop over the set of tracked points\n",
    "\tfor i in range(1, len(pts)):\n",
    "\t\t# if either of the tracked points are None, ignore\n",
    "\t\t# them\n",
    "\t\tif pts[i - 1] is None or pts[i] is None:\n",
    "\t\t\tcontinue\n",
    "\t\t# otherwise, compute the thickness of the line and\n",
    "\t\t# draw the connecting lines\n",
    "\t\tthickness = int(np.sqrt(args[\"buffer\"] / float(i + 1)) * 2.5)\n",
    "\t\tcv2.line(frame, pts[i - 1], pts[i], (0, 0, 255), thickness)\n",
    "\t# show the frame to our screen\n",
    "\tcv2.imshow(\"Frame\", frame)\n",
    "\tkey = cv2.waitKey(1) & 0xFF\n",
    "\t# if the 'q' key is pressed, stop the loop\n",
    "\tif key == ord(\"q\"):\n",
    "\t\tbreak\n",
    "# if we are not using a video file, stop the camera video stream\n",
    "if not args.get(\"video\", False):\n",
    "\tvs.stop()\n",
    "# otherwise, release the camera\n",
    "else:\n",
    "\tvs.release()\n",
    "# close all windows\n",
    "cv2.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "58bfc31e",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
